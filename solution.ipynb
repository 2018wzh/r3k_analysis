{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三国演义 分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安装依赖\n",
    "- Python=3.11\n",
    "- HanLP\n",
    "- NumPy\n",
    "- Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取源数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_src = []\n",
    "if os.path.exists(\"dataset/三国演义.txt\"):\n",
    "    with open(\"dataset/三国演义.txt\", \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        dataset_src = f.readlines()  # 逐行读取\n",
    "else:\n",
    "    print(\"文件不存在\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "dataset = []\n",
    "# 去空行\n",
    "dataset = [line.strip() for line in dataset_src if line != \"\\n\"]\n",
    "# 去除额外信息\n",
    "dataset = dataset[3:-2]\n",
    "chapter_index = []\n",
    "chapter_content = [[]]\n",
    "chapter_cnt = 0\n",
    "chinese_punctuation = r\"[,.!;:，。！：；—　。，、》《？”“]\"  # 中文标点符号\n",
    "for i in range(len(dataset)):\n",
    "    if dataset[i].startswith(\"正文\"):\n",
    "        chapter_cnt += 1\n",
    "        chapter_index.append(i)  # 获取章节索引\n",
    "        chapter_content.append([])  # 新建章节\n",
    "    else:\n",
    "        # dataset[i] = re.sub(chinese_punctuation, '', dataset[i])  # 去除标点符号\n",
    "        chapter_content[chapter_cnt].append(dataset[i])  # 获取内容\n",
    "        # 去除标点符号\n",
    "\n",
    "# 保存为json\n",
    "data = []\n",
    "for i in range(len(chapter_index)):\n",
    "    line = dataset[chapter_index[i]]\n",
    "    data.append(\n",
    "        {\n",
    "            \"chapter\": line[line.find(\"回\") + 1 :].strip(),\n",
    "            \"content\": chapter_content[i + 1],\n",
    "        }\n",
    "    )\n",
    "with open(\"dataset/dataset.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入预处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小： 120\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open(\"dataset/dataset.json\", \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    data = json.load(f)\n",
    "print(\"数据集大小：\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取章回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 787662.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "chapters = []\n",
    "for i in tqdm.tqdm(range(len(data))):\n",
    "    chapters.append(data[i][\"chapter\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"export/chapters.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(len(chapters)):\n",
    "        writer.writerow([chapters[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共120章\n",
      "第1章：宴桃园豪杰三结义 斩黄巾英雄首立功\n",
      "第2章：张翼德怒鞭督邮 何国舅谋诛宦竖\n",
      "第3章：议温明董卓叱丁原 馈金珠李肃说吕布\n",
      "第4章：废汉帝陈留践位 谋董贼孟德献刀\n",
      "第5章：发矫诏诸镇应曹公 破关兵三英战吕布\n",
      "第6章：焚金阙董卓行凶 匿玉玺孙坚背约\n",
      "第7章：袁绍磐河战公孙 孙坚跨江击刘表\n",
      "第8章：王司徒巧使连环计 董太师大闹凤仪亭\n",
      "第9章：除暴凶吕布助司徒 犯长安李傕听贾诩\n",
      "第10章：勤王室马腾举义 报父仇曹操兴师\n",
      "第11章：刘皇叔北海救孔融 吕温侯濮阳破曹操\n",
      "第12章：陶恭祖三让徐州 曹孟穗大战吕布\n",
      "第13章：李傕郭汜大交兵 杨奉董承双救驾\n",
      "第14章：曹孟德移驾幸许都 吕奉先乘夜袭徐郡\n",
      "第15章：太史慈酣斗小霸王 孙伯符大战严白虎\n",
      "第16章：吕奉先射戟辕门 曹孟德败师淯水\n",
      "第17章：袁公路大起七军 曹孟德会合三将\n",
      "第18章：贾文和料敌决胜 夏侯惇拨矢啖睛\n",
      "第19章：下邳城曹操鏖兵 白门楼吕布殒命\n",
      "第20章：曹阿瞒许田打围 董国舅内阁受诏\n",
      "第21章：曹操煮酒论英雄 关公赚城斩车胄\n",
      "第22章：袁曹各起马步三军 关张共擒王刘二将\n",
      "第23章：祢正平裸衣骂贼 吉太医下毒遭刑\n",
      "第24章：国贼行凶杀贵妃 皇叔败走投袁绍\n",
      "第25章：屯土山关公约三事 救白马曹操解重围\n",
      "第26章：袁本初败兵折将 关云长挂印封金\n",
      "第27章：美髯公千里走单骑 汉寿侯五关斩六将\n",
      "第28章：斩蔡阳兄弟释疑 会古城主臣聚义\n",
      "第29章：小霸王怒斩于吉 碧眼儿坐领江东\n",
      "第30章：战官渡本初败绩 劫乌巢孟德烧粮\n",
      "第31章：曹操仓亭破本初 玄德荆州依刘表\n",
      "第32章：夺冀州袁尚争锋 决漳河许攸献计\n",
      "第33章：曹丕乘乱纳甄氏 郭嘉遗计定辽东\n",
      "第34章：蔡夫人隔屏听密语 刘皇叔跃马过檀溪\n",
      "第35章：玄德南漳逢隐沧 单福新野遇英主\n",
      "第36章：玄德用计袭樊城 元直走马荐诸葛\n",
      "第37章：司马徽再荐名士 刘玄德三顾草庐\n",
      "第38章：定三分隆中决策 战长江孙氏报仇\n",
      "第39章：荆州城公子三求计 博望坡军师初用兵\n",
      "第40章：蔡夫人议献荆州 诸葛亮火烧新野\n",
      "第41章：刘玄德携民渡江 赵子龙单骑救主\n",
      "第42章：张翼德大闹长坂桥 刘豫州败走汉津口\n",
      "第43章：诸葛亮舌战群儒 鲁子敬力排众议\n",
      "第44章：孔明用智激周瑜 孙权决计破曹操\n",
      "第45章：三江口曹操折兵 群英会蒋干中计\n",
      "第46章：用奇谋孔明借箭 献密计黄盖受刑\n",
      "第47章：阚泽密献诈降书 庞统巧授连环计\n",
      "第48章：宴长江曹操赋诗 锁战船北军用武\n",
      "第49章：七星坛诸葛祭风 三江口周瑜纵火\n",
      "第50章：诸葛亮智算华容 关云长义释曹操\n",
      "第51章：曹仁大战东吴兵 孔明一气周公瑾\n",
      "第52章：诸葛亮智辞鲁肃 赵子龙计取桂阳\n",
      "第53章：关云长义释黄汉升 孙仲谋大战张文远\n",
      "第54章：吴国太佛寺看新郎 刘皇叔洞房续佳偶\n",
      "第55章：玄德智激孙夫人 孔明二气周公瑾\n",
      "第56章：曹操大宴铜雀台 孔明三气周公瑾\n",
      "第57章：柴桑口卧龙吊丧 耒阳县凤雏理事\n",
      "第58章：马孟起兴兵雪恨 曹阿瞒割须弃袍\n",
      "第59章：许诸裸衣斗马超 曹操抹书问韩遂\n",
      "第60章：张永年反难杨修 庞士元议取西蜀\n",
      "第61章：赵云截江夺阿斗 孙权遗书退老瞒\n",
      "第62章：取涪关杨高授首 攻雒城黄魏争功\n",
      "第63章：诸葛亮痛哭庞统 张翼德义释严颜\n",
      "第64章：孔明定计捉张任 杨阜借兵破马超\n",
      "第65章：马超大战葭萌关 刘备自领益州牧\n",
      "第66章：关云长单刀赴会 伏皇后为国捐生\n",
      "第67章：曹操平定汉中地 张辽威震逍遥津\n",
      "第68章：甘宁百骑劫魏营 左慈掷杯戏曹操\n",
      "第69章：卜周易管辂知机 讨汉贼五臣死节\n",
      "第70章：猛张飞智取瓦口隘 老黄忠计夺天荡山\n",
      "第71章：占对山黄忠逸待劳 据汉水赵云寡胜众\n",
      "第72章：诸葛亮智取汉中 曹阿瞒兵退斜谷\n",
      "第73章：玄德进位汉中王　云长攻拔襄阳郡\n",
      "第74章：庞令明抬榇决死战　关云长放水淹七军\n",
      "第75章：关云长刮骨疗毒　吕子明白衣渡江\n",
      "第76章：徐公明大战沔水　关云长败走麦城\n",
      "第77章：玉泉山关公显圣　洛阳城曹操感神\n",
      "第78章：治风疾神医身死　传遗命奸雄数终\n",
      "第79章：兄逼弟曹植赋诗　侄陷叔刘封伏法\n",
      "第80章：曹丕废帝篡炎刘　汉王正位续大统\n",
      "第81章：急兄仇张飞遇害　　雪弟恨先主兴兵\n",
      "第82章：孙权降魏受九锡　先主征吴赏六军\n",
      "第83章：战猇亭先主得仇人　守江口书生拜大将\n",
      "第84章：陆逊营烧七百里　孔明巧布八阵图\n",
      "第85章：刘先主遗诏托孤儿　诸葛亮安居平五路\n",
      "第86章：难张温秦宓逞天辩　破曹丕徐盛用火攻\n",
      "第87章：征南寇丞相大兴师　抗天兵蛮王初受执\n",
      "第88章：渡泸水再缚番王　识诈降三擒孟获\n",
      "第89章：武乡侯四番用计　南蛮王五次遭擒\n",
      "第90章：驱巨善六破蛮兵　烧藤甲七擒孟获\n",
      "第91章：祭泸水汉相班师　伐中原武侯上表\n",
      "第92章：赵子龙力斩五将　诸葛亮智取三城\n",
      "第93章：姜伯约归降孔明　武乡侯骂死王朝\n",
      "第94章：诸葛亮乘雪破羌兵　司马懿克日擒孟达\n",
      "第95章：马谡拒谏失街亭　武侯弹琴退仲达\n",
      "第96章：孔明挥泪斩马谡　周鲂断发赚曹休\n",
      "第97章：讨魏国武侯再上表　破曹兵姜维诈献书\n",
      "第98章：追汉军王双受诛　袭陈仓武侯取胜\n",
      "第99章：诸葛亮大破魏兵　司马懿入寇西蜀\n",
      "第100章：汉兵劫寨破曹真　武侯斗阵辱仲达\n",
      "第101章：出陇上诸葛妆神　奔剑阁张郃中计\n",
      "第102章：司马懿占北原渭桥　诸葛亮造木牛流马\n",
      "第103章：上方谷司马受困　五丈原诸葛禳星\n",
      "第104章：陨大星汉丞相归天　见木像魏都督丧胆\n",
      "第105章：武侯预伏锦囊计　魏主拆取承露盘\n",
      "第106章：公孙渊兵败死襄平　司马懿诈病赚曹爽\n",
      "第107章：魏主政归司马氏　姜维兵败牛头山\n",
      "第108章：丁奉雪中奋短兵　孙峻席间施密计\n",
      "第109章：困司马汉将奇谋　废曹芳魏家果报\n",
      "第110章：文鸯单骑退雄兵　姜维背水破大敌\n",
      "第111章：邓士载智败姜伯约　诸葛诞义讨司马昭\n",
      "第112章：救寿春于诠死节　取长城伯约鏖兵\n",
      "第113章：丁奉定计斩孙綝　姜维斗阵破邓艾\n",
      "第114章：曹髦驱车死南阙　姜维弃粮胜魏兵\n",
      "第115章：诏班师后主信谗　托屯田姜维避祸\n",
      "第116章：钟会分兵汉中道　武侯显圣定军山\n",
      "第117章：邓士载偷度阴平　诸葛瞻战死绵竹\n",
      "第118章：哭祖庙一王死孝　入西川二士争功\n",
      "第119章：假投降巧计成虚话　再受禅依样画葫芦\n",
      "第120章：荐杜预老将献新谋　降孙皓三分归一统\n"
     ]
    }
   ],
   "source": [
    "print(\"共{}章\".format(len(chapters)))\n",
    "for i in range(len(chapters)):\n",
    "    print(\"第{}章：{}\".format(i + 1, chapters[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载hanlp模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace_ssd/r3k_analysis/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "                                             \r"
     ]
    }
   ],
   "source": [
    "import hanlp\n",
    "import tqdm\n",
    "\n",
    "HanLP = hanlp.load(\n",
    "    hanlp.pretrained.mtl.CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_BASE_ZH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用hanlp进行分词并统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [01:38<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "person = dict()\n",
    "for i in tqdm.tqdm(range(len(data))):\n",
    "    chapter = [data[i][\"chapter\"]]\n",
    "    for j in data[i][\"content\"]:\n",
    "        chapter.append(j)\n",
    "    for j in range(len(chapter)):\n",
    "        result = HanLP(chapter[j], tasks=\"ner/msra\")\n",
    "        for k in range(len(result[\"ner/msra\"])):\n",
    "            if result[\"ner/msra\"][k][1] == \"PERSON\":\n",
    "                word = result[\"ner/msra\"][k][0]\n",
    "                if word in person:\n",
    "                    person[word][\"count\"] += 1  # 计数\n",
    "                else:\n",
    "                    # 初始化\n",
    "                    person[word] = {}\n",
    "                    person[word][\"position\"] = []\n",
    "                    person[word][\"count\"] = 1\n",
    "                person[word][\"position\"].append((i + 1, j, k + 1))  # 以三维点集记录位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取人名映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "person_map = {}\n",
    "with open(\"dataset/map.json\", \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    map_json = json.load(f)\n",
    "    for i in map_json.keys():\n",
    "        person_map[i] = set()\n",
    "        for j in map_json[i]:\n",
    "            person_map[i].add(j)\n",
    "person_dict = dict()\n",
    "person_export = dict()\n",
    "for i in person_map.keys():\n",
    "    if i not in person_export:\n",
    "        person_export[i] = {}\n",
    "    person_export[i][\"count\"] = 0\n",
    "    person_export[i][\"position\"] = set()\n",
    "    for j in person_map[i]:\n",
    "        person_dict[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in person.keys():\n",
    "    if i in person_dict:\n",
    "        person_export[person_dict[i]][\"count\"] += person[i][\"count\"]\n",
    "        for j in person[i][\"position\"]:\n",
    "            person_export[person_dict[i]][\"position\"].add(j)\n",
    "    else:\n",
    "        if len(i) >= 2:\n",
    "            person_export[i] = person[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 排序处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = []\n",
    "for i in person_export.keys():\n",
    "    pos = list(person_export[i][\"position\"])\n",
    "    pos = sorted(pos, key=lambda x: x[0])\n",
    "    persons.append([i, person_export[i][\"count\"], pos[0], pos])\n",
    "\n",
    "persons = sorted(persons, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 存储结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"export/persons.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in persons:\n",
    "        writer.writerow(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "曹操是第一主角\n",
      "第1名：曹操，共2723次\n",
      "第2名：刘备，共2105次\n",
      "第3名：诸葛亮，共1932次\n",
      "第4名：关羽，共846次\n",
      "第5名：吕布，共673次\n",
      "第6名：赵云，共585次\n",
      "第7名：司马懿，共569次\n",
      "第8名：周瑜，共566次\n",
      "第9名：孙权，共536次\n",
      "第10名：张飞，共534次\n",
      "第11名：姜维，共532次\n",
      "第12名：袁绍，共442次\n",
      "第13名：魏延，共408次\n",
      "第14名：马超，共322次\n",
      "第15名：邓艾，共293次\n",
      "第16名：董卓，共253次\n",
      "第17名：张郃，共237次\n",
      "第18名：黄忠，共234次\n",
      "第19名：孙策，共227次\n",
      "第20名：司马昭，共202次\n",
      "第21名：张辽，共184次\n",
      "第22名：徐晃，共183次\n",
      "第23名：孟获，共182次\n",
      "第24名：曹丕，共172次\n",
      "第25名：庞统，共169次\n",
      "第26名：曹仁，共162次\n",
      "第27名：关兴，共157次\n",
      "第28名：夏侯惇，共150次\n",
      "第29名：陆逊，共148次\n",
      "第30名：许褚，共145次\n",
      "第31名：刘璋，共144次\n",
      "第32名：刘表，共142次\n",
      "第33名：关平，共141次\n",
      "第34名：夏侯渊，共140次\n",
      "第35名：曹睿，共139次\n",
      "第36名：袁术，共134次\n",
      "第37名：曹真，共130次\n",
      "第38名：王允，共129次\n",
      "第39名：鲁肃，共128次\n",
      "第40名：曹洪，共126次\n",
      "第41名：庞德，共126次\n",
      "第42名：马岱，共126次\n",
      "第43名：吕蒙，共120次\n",
      "第44名：孙乾，共117次\n",
      "第45名：张苞，共117次\n",
      "第46名：太史慈，共106次\n",
      "第47名：郭汜，共104次\n",
      "第48名：王平，共101次\n",
      "第49名：郭淮，共100次\n",
      "第50名：廖化，共100次\n",
      "第51名：诸葛瑾，共98次\n",
      "第52名：张鲁，共97次\n",
      "第53名：司马，共94次\n",
      "第54名：孟达，共93次\n",
      "第55名：周泰，共91次\n",
      "第56名：李傕，共86次\n",
      "第57名：甘宁，共85次\n",
      "第58名：蔡瑁，共80次\n",
      "第59名：马腾，共79次\n",
      "第60名：李典，共78次\n",
      "第61名：张翼，共78次\n",
      "第62名：孙坚，共77次\n",
      "第63名：荀彧，共73次\n",
      "第64名：黄盖，共72次\n",
      "第65名：程普，共71次\n",
      "第66名：徐盛，共70次\n",
      "第67名：严颜，共69次\n",
      "第68名：明公，共68次\n",
      "第69名：张昭，共64次\n",
      "第70名：张任，共64次\n",
      "第71名：颜良，共61次\n",
      "第72名：诸葛，共60次\n",
      "第73名：贾诩，共58次\n",
      "第74名：钟会，共56次\n",
      "第75名：马谡，共55次\n",
      "第76名：法正，共55次\n",
      "第77名：韩当，共55次\n",
      "第78名：杨仪，共55次\n",
      "第79名：陈宫，共54次\n",
      "第80名：张嶷，共54次\n",
      "第81名：黄祖，共53次\n",
      "第82名：张梁，共52次\n",
      "第83名：孙皓，共50次\n",
      "第84名：董承，共50次\n",
      "第85名：郭嘉，共49次\n",
      "第86名：马忠，共49次\n",
      "第87名：公孙瓒，共45次\n",
      "第88名：曹休，共45次\n",
      "第89名：邓芝，共45次\n",
      "第90名：貂蝉，共44次\n",
      "第91名：糜竺，共44次\n",
      "第92名：丁奉，共44次\n",
      "第93名：曹植，共43次\n",
      "第94名：孔融，共43次\n",
      "第95名：程昱，共42次\n",
      "第96名：袁尚，共41次\n",
      "第97名：夏侯楙，共41次\n",
      "第98名：曹爽，共41次\n",
      "第99名：刘禅，共40次\n",
      "第100名：陶谦，共40次\n",
      "==========\n",
      "出场顺序:\n",
      "公孙瓒:第1章第10句\n",
      "刘备:第1章第15句\n",
      "曹植:第1章第18句\n",
      "曹操:第1章第20句\n",
      "关羽:第1章第21句\n",
      "张飞:第1章第21句\n",
      "张梁:第1章第21句\n",
      "董卓:第1章第22句\n",
      "司马:第2章第4句\n",
      "颜良:第2章第4句\n",
      "孙坚:第2章第5句\n",
      "袁绍:第2章第13句\n",
      "郭汜:第3章第2句\n",
      "李傕:第3章第2句\n",
      "袁术:第3章第5句\n",
      "王允:第3章第10句\n",
      "吕布:第3章第12句\n",
      "陈宫:第4章第11句\n",
      "曹仁:第5章第2句\n",
      "夏侯惇:第5章第2句\n",
      "夏侯渊:第5章第2句\n",
      "曹洪:第5章第2句\n",
      "马腾:第5章第3句\n",
      "孔融:第5章第3句\n",
      "陶谦:第5章第3句\n",
      "黄盖:第5章第7句\n",
      "程普:第5章第7句\n",
      "赵云:第5章第9句\n",
      "韩当:第5章第9句\n",
      "李典:第6章第5句\n",
      "刘表:第6章第10句\n",
      "蔡瑁:第6章第10句\n",
      "孙权:第7章第10句\n",
      "黄祖:第7章第10句\n",
      "孙策:第7章第16句\n",
      "魏延:第8章第5句\n",
      "貂蝉:第8章第7句\n",
      "贾诩:第9章第0句\n",
      "马超:第10章第3句\n",
      "关平:第10章第4句\n",
      "荀彧:第10章第4句\n",
      "郭嘉:第10章第4句\n",
      "程昱:第10章第4句\n",
      "严颜:第10章第5句\n",
      "明公:第10章第6句\n",
      "糜竺:第11章第1句\n",
      "吕蒙:第11章第2句\n",
      "太史慈:第11章第5句\n",
      "张辽:第11章第13句\n",
      "孙乾:第12章第8句\n",
      "许褚:第12章第10句\n",
      "徐晃:第13章第11句\n",
      "董承:第13章第11句\n",
      "司马昭:第14章第6句\n",
      "张昭:第15章第5句\n",
      "周瑜:第15章第7句\n",
      "周泰:第15章第10句\n",
      "刘璋:第16章第13句\n",
      "张鲁:第16章第13句\n",
      "张郃:第22章第72句\n",
      "黄忠:第22章第74句\n",
      "廖化:第27章第3句\n",
      "鲁肃:第29章第8句\n",
      "诸葛瑾:第29章第11句\n",
      "诸葛:第29章第11句\n",
      "袁尚:第30章第13句\n",
      "曹丕:第32章第14句\n",
      "刘禅:第34章第4句\n",
      "庞统:第35章第2句\n",
      "庞德:第35章第2句\n",
      "诸葛亮:第36章第6句\n",
      "关兴:第38章第6句\n",
      "陆逊:第38章第6句\n",
      "徐盛:第38章第6句\n",
      "丁奉:第38章第6句\n",
      "甘宁:第38章第12句\n",
      "司马懿:第39章第8句\n",
      "马谡:第52章第4句\n",
      "曹休:第56章第4句\n",
      "马岱:第57章第9句\n",
      "孟达:第60章第7句\n",
      "法正:第60章第10句\n",
      "张任:第60章第12句\n",
      "张翼:第64章第4句\n",
      "邓芝:第65章第10句\n",
      "郭淮:第70章第6句\n",
      "王平:第71章第10句\n",
      "马忠:第77章第5句\n",
      "张苞:第81章第13句\n",
      "曹真:第84章第17句\n",
      "孟获:第85章第17句\n",
      "张嶷:第87章第17句\n",
      "姜维:第91章第3句\n",
      "曹睿:第91章第15句\n",
      "杨仪:第91章第20句\n",
      "夏侯楙:第91章第25句\n",
      "曹爽:第106章第0句\n",
      "邓艾:第107章第13句\n",
      "钟会:第110章第3句\n",
      "孙皓:第113章第7句\n"
     ]
    }
   ],
   "source": [
    "print(\"{}是第一主角\".format(persons[0][0]))\n",
    "order = {}\n",
    "for i in range(100):\n",
    "    print(\"第{}名：{}，共{}次\".format(i + 1, persons[i][0], persons[i][1]))\n",
    "    order.update({persons[i][0]: persons[i][2]})\n",
    "print(\"=\" * 10)\n",
    "print(\"出场顺序:\")\n",
    "sorted_order = sorted(order.items(), key=lambda x: (x[1][0], x[1][1]))\n",
    "for name, position in sorted_order:\n",
    "    print(\"{}:第{}章第{}句\".format(name, position[0], position[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取 Task 2 中获取的数据并转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "max_cnt=10\n",
    "def parse(s):\n",
    "    # 移除方括号并分割元组字符串\n",
    "    s = s.strip(\"[]\")\n",
    "    tuple_strings = s.split(\"), (\")\n",
    "\n",
    "    result = []\n",
    "    for t in tuple_strings:\n",
    "        # 清理元组字符串\n",
    "        t = t.strip(\"()\")\n",
    "        # 分割并转换为整数\n",
    "        numbers = [int(x) for x in t.split(\", \")]\n",
    "        # 转换为元组并添加到结果列表\n",
    "        result.append(tuple(numbers))\n",
    "    return result\n",
    "\n",
    "\n",
    "persons = {}\n",
    "with open(\"export/persons.csv\", \"r\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    count = 0\n",
    "    for row in reader:\n",
    "        if count == max_cnt:\n",
    "            break\n",
    "        count += 1\n",
    "        persons[row[0]] = []\n",
    "        input_data = parse(row[3])\n",
    "        for k in input_data:\n",
    "            persons[row[0]].append(np.array(k))  # 读取位置信息并转换为向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对数据进行加权"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均每章17.441666666666666句，每句60.53441924928282词\n"
     ]
    }
   ],
   "source": [
    "# 统计平均数量\n",
    "avg_lines=0\n",
    "avg_words=0\n",
    "for i in range(len(data)):\n",
    "    avg_lines+=len(data[i][\"content\"])\n",
    "    for j in range(len(data[i][\"content\"])):\n",
    "        avg_words+=len(data[i][\"content\"][j])\n",
    "    avg_words/=len(data[i][\"content\"])\n",
    "avg_lines/=len(data)\n",
    "avg_words/=3\n",
    "print(\"平均每章{}句，每句{}词\".format(avg_lines,avg_words))\n",
    "# 加权\n",
    "for i in persons.keys():\n",
    "    for j in range(len(persons[i])):\n",
    "        persons[i][j][0]=persons[i][j][0]*avg_lines*avg_words\n",
    "        persons[i][j][1]=persons[i][j][1]*avg_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算相关度\n",
    "- 使用点集中的点到点集的最邻近距离计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用GPU加速计算\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 26.95it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc(persons):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dis = {}\n",
    "\n",
    "    # 预处理：将numpy数组转换为单个tensor\n",
    "    person_tensors = {\n",
    "        k: torch.from_numpy(np.array(v, dtype=np.float32)).to(device)\n",
    "        for k, v in persons.items()\n",
    "    }\n",
    "\n",
    "    for i in tqdm(person_tensors.keys()):\n",
    "        for j in person_tensors.keys():\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            points_i = person_tensors[i]\n",
    "            points_j = person_tensors[j]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # 计算距离\n",
    "                distances = torch.cdist(points_i, points_j, p=1)\n",
    "                min_distances = torch.min(distances, dim=1)[0]\n",
    "                dis[(i, j)] = float(torch.mean(min_distances).cpu())\n",
    "\n",
    "    return dis\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"使用GPU加速计算\")\n",
    "else:\n",
    "    print(\"使用CPU计算\")\n",
    "\n",
    "dis = calc(persons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 排序并储存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"export/distance.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    dis_sorted = sorted(dis.items(), key=lambda x: x[1])\n",
    "    for relation, distance in dis_sorted:\n",
    "        writer.writerow([relation[0], relation[1], distance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1近的关系：周瑜和曹操，距离为8720.037109375\n",
      "第2近的关系：司马懿和诸葛亮，距离为23330.90625\n",
      "第3近的关系：张飞和刘备，距离为26015.28125\n",
      "第4近的关系：刘备和曹操，距离为61199.3828125\n",
      "第5近的关系：张飞和曹操，距离为76769.015625\n",
      "第6近的关系：关羽和曹操，距离为124450.4765625\n",
      "第7近的关系：关羽和刘备，距离为206526.890625\n",
      "第8近的关系：周瑜和刘备，距离为272244.625\n",
      "第9近的关系：曹操和刘备，距离为276834.0\n",
      "第10近的关系：刘备和张飞，距离为363248.78125\n",
      "第11近的关系：吕布和曹操，距离为473303.75\n",
      "第12近的关系：周瑜和孙权，距离为475874.78125\n",
      "第13近的关系：刘备和关羽，距离为540640.9375\n",
      "第14近的关系：孙权和曹操，距离为546298.8125\n",
      "第15近的关系：赵云和曹操，距离为547632.0\n",
      "第16近的关系：关羽和赵云，距离为730768.9375\n",
      "第17近的关系：吕布和刘备，距离为742915.125\n",
      "第18近的关系：张飞和关羽，距离为795325.75\n",
      "第19近的关系：关羽和张飞，距离为822762.5\n",
      "第20近的关系：吕布和关羽，距离为823639.5\n",
      "第21近的关系：周瑜和张飞，距离为844390.75\n",
      "第22近的关系：周瑜和赵云，距离为859221.6875\n",
      "第23近的关系：孙权和刘备，距离为866656.9375\n",
      "第24近的关系：周瑜和关羽，距离为904098.25\n",
      "第25近的关系：张飞和赵云，距离为1011295.75\n",
      "第26近的关系：曹操和张飞，距离为1048184.6875\n",
      "第27近的关系：吕布和张飞，距离为1057627.25\n",
      "第28近的关系：刘备和赵云，距离为1058997.5\n",
      "第29近的关系：诸葛亮和孙权，距离为1106353.625\n",
      "第30近的关系：曹操和关羽，距离为1146432.625\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(\"第{}近的关系：{}和{}，距离为{}\".format(i + 1, dis_sorted[i][0][0], dis_sorted[i][0][1], dis_sorted[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取人物名单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "person_list = []\n",
    "with open(\"export/person.csv\", \"r\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    count = 0\n",
    "    for row in reader:\n",
    "        if count == 20:\n",
    "            break\n",
    "        count += 1\n",
    "        person_list.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行词向量转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace_ssd/r3k_analysis/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tqdm\n",
    "# 加载模型\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "# 定义关键词\n",
    "keywords = [\"胜\", \"败\", \"克\", \"擒\", \"大败\", \"捷\", \"破\", \"取\", \"降\"]\n",
    "keyword_embeddings = model.encode(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-2.45404154e-01  5.91705382e-01  5.33690393e-01  1.84479430e-02\n -5.04138470e-01 -2.06162915e-01  1.11922526e+00  1.89100757e-01\n  6.99254453e-01 -4.34618235e-01  5.12407839e-01 -1.26707411e+00\n  2.97268897e-01 -1.60574839e-01  2.99710155e-01 -1.45805731e-01\n  2.10144714e-01  2.89475948e-01 -7.56933808e-01 -1.16780490e-01\n -7.96204656e-02  6.20231688e-01  5.61652891e-02 -1.11111887e-02\n  1.79787904e-01  8.98607150e-02  4.38831061e-01  7.00074613e-01\n  1.20653346e-01  3.17143410e-01  2.67180324e-01  3.00351650e-01\n -1.90911070e-01  5.33366919e-01  1.99243560e-01  5.93145907e-01\n -3.40085834e-01 -4.59780544e-02  2.09262654e-01 -9.68891904e-02\n -1.80566862e-01 -1.81853443e-01  9.19886827e-01  1.92857891e-01\n  4.93163645e-01  4.21973646e-01 -6.11091815e-02 -2.44281311e-02\n -3.79558682e-01  2.94650048e-01 -2.51497030e-01 -2.12196499e-01\n  3.99188474e-02  1.43035054e-01  4.35351253e-01  2.89106611e-02\n  3.75047117e-01  7.72809237e-02 -9.66342464e-02  7.59231448e-02\n -3.32247823e-01 -2.56433501e-04 -6.27177298e-01  2.88210005e-01\n -6.56172335e-02  1.72804236e-01 -1.14144079e-01  3.39114010e-01\n  2.27046102e-01  9.32658613e-02 -1.58897623e-01  1.72786653e-01\n  1.09550998e-01 -4.35620576e-01 -7.07463145e-01 -4.81825322e-01\n  3.62152219e-01  3.29082072e-01 -4.85541761e-01  2.34044194e-01\n  2.68634260e-01 -1.00321313e-02 -4.94138628e-01  3.51411812e-02\n -2.69216001e-01  3.09938639e-01  5.46081439e-02 -3.52690890e-02\n  1.05450213e-01 -1.41362295e-01 -2.02495918e-01  9.39487159e-01\n -1.84791442e-02  4.11839575e-01 -5.24189770e-01 -5.70808947e-02\n  3.00666597e-02 -7.31944203e-01 -7.54748464e-01  5.99832721e-02\n  3.01403314e-01  5.40538251e-01 -2.68781155e-01  7.48244703e-01\n -5.52746415e-01 -9.68166649e-01 -1.49196431e-01 -4.39275056e-01\n -3.30425113e-01  2.31400371e-01 -7.74182677e-01 -7.65110493e-01\n -1.07685015e-01  1.36507630e-01 -1.08972445e-01  2.24567652e-02\n -7.83729181e-02  2.51854151e-01 -1.85405258e-02 -1.88449323e-01\n  1.71071719e-02  1.80089116e-01 -4.46721315e-01 -2.63689220e-01\n -7.73849666e-01  1.14539310e-01  9.16354358e-02 -1.99393891e-02\n  2.30254978e-01  4.29362327e-01  1.16087645e-01  2.67403703e-02\n -2.96590358e-01  3.52357477e-01 -8.58231559e-02  1.08387969e-01\n  2.23839372e-01 -9.35890153e-03 -2.09893882e-01  3.71115416e-01\n -4.80928689e-01 -9.14872661e-02  3.43579426e-02 -1.71616167e-01\n -3.36254925e-01  3.82117659e-01  4.96874779e-01  3.40159889e-03\n  6.50883988e-02 -1.57129779e-01  1.39715433e-01 -3.81323010e-01\n -7.32205138e-02  3.48391086e-01  7.60034502e-01 -1.10926174e-01\n -1.35483384e-01  8.94865274e-01  5.68485141e-01  3.62560183e-01\n -5.98918349e-02  6.54144138e-02 -9.02893469e-02  1.13398686e-01\n -5.18697560e-01  5.70536032e-02  4.87054838e-03 -2.06811517e-01\n  2.07762420e-01 -2.24109247e-01 -4.49084103e-01  1.57683238e-01\n  4.66177970e-01  4.29018825e-01 -7.36544371e-01 -5.28453052e-01\n  2.89126217e-01  2.87981272e-01 -2.09560350e-01 -3.20377439e-01\n  1.25815883e-01  8.87519196e-02  1.58219740e-01 -6.75486550e-02\n -3.60414088e-02  4.90541570e-02 -6.96634829e-01  4.76305038e-01\n -4.04750824e-01 -6.76565707e-01 -4.25603420e-01 -6.10554159e-01\n  2.72153705e-01 -9.45224985e-02  1.50089860e-01 -2.80363441e-01\n  4.76847738e-01 -4.85435843e-01 -1.68497145e-01 -1.08914517e-01\n  4.67869341e-01  3.41736972e-01 -1.32950529e-01 -1.29736021e-01\n  1.91345755e-02 -8.63667205e-02  7.04652250e-01  3.60468328e-02\n -9.01101530e-01  1.63295463e-01 -3.79026592e-01 -1.31572947e-01\n  1.61050990e-01  1.36069998e-01  4.89884824e-01  4.81140241e-02\n  1.82033539e-01 -1.98794767e-01 -1.32256317e+00  2.74666976e-02\n  5.82364798e-01 -5.39436162e-01 -2.67074466e-01 -6.47620261e-01\n  6.18418790e-02  4.41093892e-01 -7.39565670e-01 -7.10227862e-02\n  3.00719589e-01 -2.92588860e-01  6.39174134e-02  9.52150941e-01\n  2.05524638e-01  2.91149914e-01 -5.70359707e-01  3.25282127e-01\n  6.09877557e-02 -1.54548183e-01 -1.27960354e-01  2.21288458e-01\n  4.63643342e-01  1.10557884e-01 -2.25788027e-01  5.98286390e-01\n -2.39060447e-01 -5.38098156e-01 -8.26513827e-01  5.57227969e-01\n -2.36915454e-01  8.72446001e-01  6.39080048e-01  1.72972586e-02\n -3.26353431e-01  1.98174462e-01  5.84650226e-02 -6.80877745e-01\n -6.08730674e-01  1.18987180e-01 -5.03392041e-01 -7.01047063e-01\n  2.98430622e-01 -3.20620507e-01 -7.46304840e-02 -1.93215325e-01\n -1.33412763e-01 -7.15566501e-02  3.56738746e-01  5.05173862e-01\n  8.93933326e-02 -2.38836586e-01 -3.82158160e-01 -1.43535867e-01\n -2.63314843e-01 -1.50756270e-01  8.14791396e-02 -6.98975146e-01\n  4.72311586e-01  1.85273632e-01  3.17287713e-01  3.00824076e-01\n  1.20420858e-01 -1.07572138e+00 -4.55684572e-01  1.88214660e-01\n -1.08345792e-01  7.96756446e-02  5.01708686e-01  3.00650537e-01\n -7.76234150e-01  4.91459593e-02  3.12419742e-01  4.01974291e-01\n  4.74411249e-01 -4.13482577e-01  3.14851522e-01  2.01868877e-01\n -2.66524166e-01 -2.89674759e-01 -3.49960715e-01  1.16209179e-01\n  1.56035155e-01  2.70763248e-01  6.97787926e-02 -5.04150867e-01\n  2.04168800e-02  1.92459300e-01 -5.10688312e-03 -1.19470835e-01\n  7.44104624e-01 -9.09344196e-01 -3.88829201e-01  4.15858448e-01\n  2.66474277e-01 -1.12689532e-01 -6.23039752e-02  3.79456371e-01\n -5.87040722e-01  1.18184187e-01  2.25359082e-01  1.95421308e-01\n -6.41170442e-01  1.17639430e-01  1.98394969e-01 -8.18616033e-01\n  2.52713293e-01 -5.67709506e-01 -7.71199018e-02 -6.47520721e-02\n  4.16792095e-01  2.45681494e-01 -1.99627340e-01 -1.10730484e-01\n -1.05805129e-01  1.12036377e-01 -1.87683105e-03  3.39559138e-01\n  4.57511187e-01 -1.87834010e-01 -8.80134761e-01 -5.58655977e-01\n -1.05384208e-01 -4.24830705e-01 -3.23958308e-01 -3.67931277e-01\n -7.22977221e-01  3.04751784e-01 -7.91982889e-01 -7.62918070e-02\n -3.32580805e-01  2.68659085e-01 -2.07510799e-01  5.45179069e-01\n  4.42066759e-01 -7.39150107e-01 -2.91386455e-01  2.38069400e-01\n  3.63228261e-01 -6.54361844e-02  4.98770058e-01 -8.21933523e-02\n  4.38411802e-01 -4.23176497e-01  4.74970698e-01  1.37497044e+00\n  8.63339007e-02  6.23613410e-02  3.97016078e-01 -2.45513573e-01\n -3.45114589e-01  3.40367019e-01  6.25867248e-02  6.21372998e-01\n  6.69600427e-01  2.77631730e-01 -9.81509238e-02  3.42925936e-01\n  3.59222256e-02  6.04213476e-01 -5.42873859e-01  7.87818525e-03\n  1.22123504e+00 -4.71222490e-01  1.55979961e-01  5.49254775e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chapter \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(data):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m chapter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 26\u001b[0m         line_results \u001b[38;5;241m=\u001b[39m \u001b[43mvectorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(line_results)\n",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mvectorize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m sentence_embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(text, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 计算与关键词的相似度\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43msentence_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeyword_embeddings\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 找到最相似的关键词\u001b[39;00m\n\u001b[1;32m     13\u001b[0m max_index \u001b[38;5;241m=\u001b[39m similarities[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margmax()\n",
      "File \u001b[0;32m/mnt/workspace_ssd/r3k_analysis/.conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/workspace_ssd/r3k_analysis/.conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1679\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \n\u001b[1;32m   1637\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1679\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1681\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m/mnt/workspace_ssd/r3k_analysis/.conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:185\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[1;32m    175\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    176\u001b[0m         X,\n\u001b[1;32m    177\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    195\u001b[0m         Y,\n\u001b[1;32m    196\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[0;32m/mnt/workspace_ssd/r3k_analysis/.conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m             )\n\u001b[0;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-2.45404154e-01  5.91705382e-01  5.33690393e-01  1.84479430e-02\n -5.04138470e-01 -2.06162915e-01  1.11922526e+00  1.89100757e-01\n  6.99254453e-01 -4.34618235e-01  5.12407839e-01 -1.26707411e+00\n  2.97268897e-01 -1.60574839e-01  2.99710155e-01 -1.45805731e-01\n  2.10144714e-01  2.89475948e-01 -7.56933808e-01 -1.16780490e-01\n -7.96204656e-02  6.20231688e-01  5.61652891e-02 -1.11111887e-02\n  1.79787904e-01  8.98607150e-02  4.38831061e-01  7.00074613e-01\n  1.20653346e-01  3.17143410e-01  2.67180324e-01  3.00351650e-01\n -1.90911070e-01  5.33366919e-01  1.99243560e-01  5.93145907e-01\n -3.40085834e-01 -4.59780544e-02  2.09262654e-01 -9.68891904e-02\n -1.80566862e-01 -1.81853443e-01  9.19886827e-01  1.92857891e-01\n  4.93163645e-01  4.21973646e-01 -6.11091815e-02 -2.44281311e-02\n -3.79558682e-01  2.94650048e-01 -2.51497030e-01 -2.12196499e-01\n  3.99188474e-02  1.43035054e-01  4.35351253e-01  2.89106611e-02\n  3.75047117e-01  7.72809237e-02 -9.66342464e-02  7.59231448e-02\n -3.32247823e-01 -2.56433501e-04 -6.27177298e-01  2.88210005e-01\n -6.56172335e-02  1.72804236e-01 -1.14144079e-01  3.39114010e-01\n  2.27046102e-01  9.32658613e-02 -1.58897623e-01  1.72786653e-01\n  1.09550998e-01 -4.35620576e-01 -7.07463145e-01 -4.81825322e-01\n  3.62152219e-01  3.29082072e-01 -4.85541761e-01  2.34044194e-01\n  2.68634260e-01 -1.00321313e-02 -4.94138628e-01  3.51411812e-02\n -2.69216001e-01  3.09938639e-01  5.46081439e-02 -3.52690890e-02\n  1.05450213e-01 -1.41362295e-01 -2.02495918e-01  9.39487159e-01\n -1.84791442e-02  4.11839575e-01 -5.24189770e-01 -5.70808947e-02\n  3.00666597e-02 -7.31944203e-01 -7.54748464e-01  5.99832721e-02\n  3.01403314e-01  5.40538251e-01 -2.68781155e-01  7.48244703e-01\n -5.52746415e-01 -9.68166649e-01 -1.49196431e-01 -4.39275056e-01\n -3.30425113e-01  2.31400371e-01 -7.74182677e-01 -7.65110493e-01\n -1.07685015e-01  1.36507630e-01 -1.08972445e-01  2.24567652e-02\n -7.83729181e-02  2.51854151e-01 -1.85405258e-02 -1.88449323e-01\n  1.71071719e-02  1.80089116e-01 -4.46721315e-01 -2.63689220e-01\n -7.73849666e-01  1.14539310e-01  9.16354358e-02 -1.99393891e-02\n  2.30254978e-01  4.29362327e-01  1.16087645e-01  2.67403703e-02\n -2.96590358e-01  3.52357477e-01 -8.58231559e-02  1.08387969e-01\n  2.23839372e-01 -9.35890153e-03 -2.09893882e-01  3.71115416e-01\n -4.80928689e-01 -9.14872661e-02  3.43579426e-02 -1.71616167e-01\n -3.36254925e-01  3.82117659e-01  4.96874779e-01  3.40159889e-03\n  6.50883988e-02 -1.57129779e-01  1.39715433e-01 -3.81323010e-01\n -7.32205138e-02  3.48391086e-01  7.60034502e-01 -1.10926174e-01\n -1.35483384e-01  8.94865274e-01  5.68485141e-01  3.62560183e-01\n -5.98918349e-02  6.54144138e-02 -9.02893469e-02  1.13398686e-01\n -5.18697560e-01  5.70536032e-02  4.87054838e-03 -2.06811517e-01\n  2.07762420e-01 -2.24109247e-01 -4.49084103e-01  1.57683238e-01\n  4.66177970e-01  4.29018825e-01 -7.36544371e-01 -5.28453052e-01\n  2.89126217e-01  2.87981272e-01 -2.09560350e-01 -3.20377439e-01\n  1.25815883e-01  8.87519196e-02  1.58219740e-01 -6.75486550e-02\n -3.60414088e-02  4.90541570e-02 -6.96634829e-01  4.76305038e-01\n -4.04750824e-01 -6.76565707e-01 -4.25603420e-01 -6.10554159e-01\n  2.72153705e-01 -9.45224985e-02  1.50089860e-01 -2.80363441e-01\n  4.76847738e-01 -4.85435843e-01 -1.68497145e-01 -1.08914517e-01\n  4.67869341e-01  3.41736972e-01 -1.32950529e-01 -1.29736021e-01\n  1.91345755e-02 -8.63667205e-02  7.04652250e-01  3.60468328e-02\n -9.01101530e-01  1.63295463e-01 -3.79026592e-01 -1.31572947e-01\n  1.61050990e-01  1.36069998e-01  4.89884824e-01  4.81140241e-02\n  1.82033539e-01 -1.98794767e-01 -1.32256317e+00  2.74666976e-02\n  5.82364798e-01 -5.39436162e-01 -2.67074466e-01 -6.47620261e-01\n  6.18418790e-02  4.41093892e-01 -7.39565670e-01 -7.10227862e-02\n  3.00719589e-01 -2.92588860e-01  6.39174134e-02  9.52150941e-01\n  2.05524638e-01  2.91149914e-01 -5.70359707e-01  3.25282127e-01\n  6.09877557e-02 -1.54548183e-01 -1.27960354e-01  2.21288458e-01\n  4.63643342e-01  1.10557884e-01 -2.25788027e-01  5.98286390e-01\n -2.39060447e-01 -5.38098156e-01 -8.26513827e-01  5.57227969e-01\n -2.36915454e-01  8.72446001e-01  6.39080048e-01  1.72972586e-02\n -3.26353431e-01  1.98174462e-01  5.84650226e-02 -6.80877745e-01\n -6.08730674e-01  1.18987180e-01 -5.03392041e-01 -7.01047063e-01\n  2.98430622e-01 -3.20620507e-01 -7.46304840e-02 -1.93215325e-01\n -1.33412763e-01 -7.15566501e-02  3.56738746e-01  5.05173862e-01\n  8.93933326e-02 -2.38836586e-01 -3.82158160e-01 -1.43535867e-01\n -2.63314843e-01 -1.50756270e-01  8.14791396e-02 -6.98975146e-01\n  4.72311586e-01  1.85273632e-01  3.17287713e-01  3.00824076e-01\n  1.20420858e-01 -1.07572138e+00 -4.55684572e-01  1.88214660e-01\n -1.08345792e-01  7.96756446e-02  5.01708686e-01  3.00650537e-01\n -7.76234150e-01  4.91459593e-02  3.12419742e-01  4.01974291e-01\n  4.74411249e-01 -4.13482577e-01  3.14851522e-01  2.01868877e-01\n -2.66524166e-01 -2.89674759e-01 -3.49960715e-01  1.16209179e-01\n  1.56035155e-01  2.70763248e-01  6.97787926e-02 -5.04150867e-01\n  2.04168800e-02  1.92459300e-01 -5.10688312e-03 -1.19470835e-01\n  7.44104624e-01 -9.09344196e-01 -3.88829201e-01  4.15858448e-01\n  2.66474277e-01 -1.12689532e-01 -6.23039752e-02  3.79456371e-01\n -5.87040722e-01  1.18184187e-01  2.25359082e-01  1.95421308e-01\n -6.41170442e-01  1.17639430e-01  1.98394969e-01 -8.18616033e-01\n  2.52713293e-01 -5.67709506e-01 -7.71199018e-02 -6.47520721e-02\n  4.16792095e-01  2.45681494e-01 -1.99627340e-01 -1.10730484e-01\n -1.05805129e-01  1.12036377e-01 -1.87683105e-03  3.39559138e-01\n  4.57511187e-01 -1.87834010e-01 -8.80134761e-01 -5.58655977e-01\n -1.05384208e-01 -4.24830705e-01 -3.23958308e-01 -3.67931277e-01\n -7.22977221e-01  3.04751784e-01 -7.91982889e-01 -7.62918070e-02\n -3.32580805e-01  2.68659085e-01 -2.07510799e-01  5.45179069e-01\n  4.42066759e-01 -7.39150107e-01 -2.91386455e-01  2.38069400e-01\n  3.63228261e-01 -6.54361844e-02  4.98770058e-01 -8.21933523e-02\n  4.38411802e-01 -4.23176497e-01  4.74970698e-01  1.37497044e+00\n  8.63339007e-02  6.23613410e-02  3.97016078e-01 -2.45513573e-01\n -3.45114589e-01  3.40367019e-01  6.25867248e-02  6.21372998e-01\n  6.69600427e-01  2.77631730e-01 -9.81509238e-02  3.42925936e-01\n  3.59222256e-02  6.04213476e-01 -5.42873859e-01  7.87818525e-03\n  1.22123504e+00 -4.71222490e-01  1.55979961e-01  5.49254775e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
